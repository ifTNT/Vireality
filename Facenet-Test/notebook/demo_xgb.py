# -*- coding: utf-8 -*-
"""demo-svm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5JtcZz8YNIDh7rCcKlkBIybJS2WLtlD
"""

# Commented out IPython magic to ensure Python compatibility.
import time
import numpy as np
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

import matplotlib.pyplot as plt
import cv2
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from imageio import imread
from skimage.transform import resize
from keras.models import load_model
from joblib import dump, load
import xgboost as xgb
from xgboost import XGBClassifier

# %matplotlib inline
start = time.time()

cascade_path = os.path.abspath('../model/cv2/haarcascade_frontalface_alt2.xml')

image_dir_basepath = os.path.abspath('../data/images/train')+'/'

names = os.listdir(image_dir_basepath)
#names.remove('Test')

image_size = 160
print('load names list : ' + str(time.time()-start))
last = time.time()

model_path = os.path.abspath('../model/keras/model/facenet_keras.h5')
model = load_model(model_path)

print('load model : ' + str(time.time()-last))
last = time.time()

def prewhiten(x):
    if x.ndim == 4:
        axis = (1, 2, 3)
        size = x[0].size
    elif x.ndim == 3:
        axis = (0, 1, 2)
        size = x.size
    else:
        raise ValueError('Dimension should be 3 or 4')

    mean = np.mean(x, axis=axis, keepdims=True)
    std = np.std(x, axis=axis, keepdims=True)
    std_adj = np.maximum(std, 1.0/np.sqrt(size))
    y = (x - mean) / std_adj
    return y

def l2_normalize(x, axis=-1, epsilon=1e-10):
    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))
    return output

def load_and_align_images(filepaths, margin):
    cascade = cv2.CascadeClassifier(cascade_path)

    aligned_images = []
    for filepath in filepaths:
        # print(filepath)
        img = imread(filepath)

        faces = cascade.detectMultiScale(img,
                                         scaleFactor=1.1,
                                         minNeighbors=3)
        (x, y, w, h) = faces[0]
        cropped = img[y-margin//2:y+h+margin//2,
                      x-margin//2:x+w+margin//2, :]
        aligned = resize(cropped, (image_size, image_size), mode='reflect')
        aligned_images.append(aligned)

    return np.array(aligned_images)

def calc_embs(filepaths, margin=10, batch_size=1):
    aligned_images = prewhiten(load_and_align_images(filepaths, margin))
    pd = []
    for start in range(0, len(aligned_images), batch_size):
        pd.append(model.predict_on_batch(aligned_images[start:start+batch_size]))
    embs = l2_normalize(np.concatenate(pd))

    return embs
# data = {}
def calc_dist(img_name0, img_name1):
    return distance.euclidean(a,b)
def train(dir_basepath, names, max_num_img=10):
    labels = []
    embs = []
    for name in names:
        dirpath = os.path.abspath(dir_basepath + name)
        filepaths = [os.path.join(dirpath, f) for f in os.listdir(dirpath)][:max_num_img]
        embs_ = calc_embs(filepaths)
        # for i in range(len(filepaths)):
        #   data['{}{}'.format(name, i)] = {'image_filepath' : filepaths[i],
        #                                 'emb' : embs_[i]}
        labels.extend([name] * len(embs_))
        embs.append(embs_)

    print('compute each emb : ' + str(time.time()-last))
    lastt = time.time()

    embs = np.concatenate(embs)
    le = LabelEncoder().fit(labels)
    y = le.transform(labels)
    param = {
        'max_depth': 256,
        'eta': 1,
        'objective': 'multi:softprob',
        'num_class': len(names)
    }
    dtrain = xgb.DMatrix(embs, label=y)
    num_passes = 5
    bst = xgb.train(param, dtrain, num_passes)
    #clf = XGBClassifier()
    #clf = clf.fit(embs, y)
    #clf = SVC(kernel='linear', probability=True).fit(embs, y)
    return le, bst

def infer(le, clf, filepaths):
    embs = calc_embs(filepaths)
    pred = le.inverse_transform(clf.predict(embs))
    return pred


le, bst = train(image_dir_basepath, names)
# print(le.classes_)
dump(le, "train_le.joblib")
bst.save_model('xgb_face.model')
# dump(clf, "train_model.joblib")
# start = time.time()
# test_dirpath = os.path.join(image_dir_basepath, 'Test')
# test_filepaths = [os.path.join(test_dirpath, f) for f in os.listdir(test_dirpath)]

# pred = infer(le, clf, test_filepaths)

# # fig, axes = plt.subplots(1, 1, figsize=(10, 5))

# for i in range(1):
# print('Prediction : '+str(pred[0]))
#     # axes[i].set_title('Prediction : '+str(pred[i]))
#     # axes[i].imshow(imread(test_filepaths[i]))
#     # axes[i].set_xticks([])
#     # axes[i].set_yticks([])
# # plt.show()
# print(time.time()-start)


