# -*- coding: utf-8 -*-
"""demo-svm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5JtcZz8YNIDh7rCcKlkBIybJS2WLtlD
"""

# Commented out IPython magic to ensure Python compatibility.
import time
import numpy as np
import os
import matplotlib.pyplot as plt
import cv2
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from imageio import imread
from skimage.transform import resize
from keras.models import load_model
from joblib import dump, load
from scipy.spatial import distance

# %matplotlib inline

cascade_path = 'C:/Users/User/Desktop/Facenet-Test/model/cv2/haarcascade_frontalface_alt2.xml'

image_dir_basepath = 'C:/Users/User/Desktop/Facenet-Test/data/images/'
names = os.listdir(image_dir_basepath)
names.remove('Test')
image_size = 160

model_path = 'C:/Users/User/Desktop/Facenet-Test/model/keras/model/facenet_keras.h5'
model = load_model(model_path)

def prewhiten(x):
    if x.ndim == 4:
        axis = (1, 2, 3)
        size = x[0].size
    elif x.ndim == 3:
        axis = (0, 1, 2)
        size = x.size
    else:
        raise ValueError('Dimension should be 3 or 4')

    mean = np.mean(x, axis=axis, keepdims=True)
    std = np.std(x, axis=axis, keepdims=True)
    std_adj = np.maximum(std, 1.0/np.sqrt(size))
    y = (x - mean) / std_adj
    return y

def l2_normalize(x, axis=-1, epsilon=1e-10):
    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))
    return output

def load_and_align_images(filepaths, margin):
    cascade = cv2.CascadeClassifier(cascade_path)
    
    aligned_images = []
    for filepath in filepaths:
        img = imread(filepath)

        faces = cascade.detectMultiScale(img,
                                         scaleFactor=1.1,
                                         minNeighbors=3)
        (x, y, w, h) = faces[0]
        cropped = img[y-margin//2:y+h+margin//2,
                      x-margin//2:x+w+margin//2, :]
        aligned = resize(cropped, (image_size, image_size), mode='reflect')
        aligned_images.append(aligned)
            
    return np.array(aligned_images)

def calc_embs(filepaths, margin=10, batch_size=1):
    aligned_images = prewhiten(load_and_align_images(filepaths, margin))
    pd = []
    for start in range(0, len(aligned_images), batch_size):
        pd.append(model.predict_on_batch(aligned_images[start:start+batch_size]))
    embs = l2_normalize(np.concatenate(pd))

    return embs
# data = {}
def calc_dist(people, test):
    return distance.euclidean(people,test)

def train(dir_basepath, names, max_num_img=10):
    labels = []
    embs = []
    embs_add = np.zeros([len(names),128])
    for name in names:
        dirpath = os.path.abspath(dir_basepath + name)
        filepaths = [os.path.join(dirpath, f) for f in os.listdir(dirpath)][:max_num_img]
        embs_ = calc_embs(filepaths)
        # labels.extend([name] * len(embs_))
        embs.append(embs_)
    
    for i in range(len(embs)):
        sum_ = np.zeros(128)
        for j in range(len(embs[i])):
            sum_ = sum_+embs[i][j]
        # /2 /3
        # print(embs[i].shape[0])
        embs_add[i] = sum_ / embs[i].shape[0]
    # embs = np.concatenate(embs)
    # le = LabelEncoder().fit(labels)
    # y = le.transform(labels)
    # clf = SVC(kernel='linear', probability=True).fit(embs, y)
    return  embs_add

# def infer(embs, filepaths):
#     test_embs = calc_embs(filepaths)
#     distance = np.zeros(len(names))
#     for i in range(len(embs)):
#         distance[i] = calc_dist(embs[i],test_embs[0])
#     min_index = np.argmin(distance)
#     if distance[min_index] > 0.9 : return 'unknown'
#     # pred = le.inverse_transform(clf.predict(embs))
#     return names[min_index]
    

embs = train(image_dir_basepath, names)
# print(le.classes_)
dump(names, "train_names.joblib")
dump(embs, "train_embs.joblib")
# start = time.time()
# test_dirpath = os.path.join(image_dir_basepath, 'Test')
# test_filepaths = [os.path.join(test_dirpath, f) for f in os.listdir(test_dirpath)]

# pred = infer(embs,test_filepaths)

# # fig, axes = plt.subplots(1, 1, figsize=(10, 5))

# # for i in range(1):
# print('Prediction : '+str(pred))
#     # axes[i].set_title('Prediction : '+str(pred[i]))
#     # axes[i].imshow(imread(test_filepaths[i]))
#     # axes[i].set_xticks([])
#     # axes[i].set_yticks([])
# # plt.show()
# print(time.time()-start)


